{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Mount the drive"
      ],
      "metadata": {
        "id": "RMwCqyqbd8AR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGwxr-7Ld4-H",
        "outputId": "368cfcea-f2c4-4317-93f8-2f9a876b4414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Process mining course/final_project')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the libraries"
      ],
      "metadata": {
        "id": "D-9btAehfTCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2dZL2feTfUwt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "zADouvp9fgyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'creditcard.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_hKOA_vQfXKJ",
        "outputId": "150244c1-7f0c-49de-dcf1-a905172cd589"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Time        V1        V2        V3        V4        V5        V6  \\\n",
              "0          0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "1          0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "2          1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3          1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4          2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "39994  40049 -2.856643 -1.580895  1.183275 -1.862689 -2.579951 -1.043656   \n",
              "39995  40049 -1.051131  0.606656  0.441297  0.590587 -0.118730  1.010767   \n",
              "39996  40049  1.188332  0.360587 -0.024267  1.179898 -0.095200 -0.975171   \n",
              "39997  40050  1.038810 -2.090833  0.852849 -0.847290 -2.112321  0.291188   \n",
              "39998  40052  1.211027  0.614544 -0.459212  0.900736  0.135725 -1.175774   \n",
              "\n",
              "             V7        V8        V9  ...       V21       V22       V23  \\\n",
              "0      0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
              "1     -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
              "2      0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
              "3      0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
              "4      0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "39994 -1.007610  0.919906 -1.879716  ... -0.012102 -0.304192 -0.142939   \n",
              "39995  2.282192 -0.751310  0.141134  ... -0.168207  0.495169 -0.066540   \n",
              "39996  0.403633 -0.160097 -0.460291  ...  0.063470  0.115945 -0.129453   \n",
              "39997 -1.321491  0.007713 -0.771225  ... -0.059743  0.138289 -0.341212   \n",
              "39998  0.337603 -0.198540 -0.188104  ... -0.105254 -0.214124 -0.013156   \n",
              "\n",
              "            V24       V25       V26       V27       V28  Amount  Class  \n",
              "0      0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1     -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2     -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3     -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4      0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
              "...         ...       ...       ...       ...       ...     ...    ...  \n",
              "39994  0.659917  0.200746 -0.314130  0.273768 -0.199219  215.09      0  \n",
              "39995 -0.904026 -0.149187 -0.302797 -0.188726 -0.248812  280.18      0  \n",
              "39996  0.527456  0.748484 -0.308659 -0.022350  0.003130   15.33      0  \n",
              "39997 -0.045303  0.516037  0.016258  0.051843  0.061811  236.19      0  \n",
              "39998  0.287419  0.453268  0.378507 -0.013994  0.042698    0.76      0  \n",
              "\n",
              "[39999 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e53a9e30-1c6d-42d5-8f0c-166bda049b09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39994</th>\n",
              "      <td>40049</td>\n",
              "      <td>-2.856643</td>\n",
              "      <td>-1.580895</td>\n",
              "      <td>1.183275</td>\n",
              "      <td>-1.862689</td>\n",
              "      <td>-2.579951</td>\n",
              "      <td>-1.043656</td>\n",
              "      <td>-1.007610</td>\n",
              "      <td>0.919906</td>\n",
              "      <td>-1.879716</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012102</td>\n",
              "      <td>-0.304192</td>\n",
              "      <td>-0.142939</td>\n",
              "      <td>0.659917</td>\n",
              "      <td>0.200746</td>\n",
              "      <td>-0.314130</td>\n",
              "      <td>0.273768</td>\n",
              "      <td>-0.199219</td>\n",
              "      <td>215.09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>40049</td>\n",
              "      <td>-1.051131</td>\n",
              "      <td>0.606656</td>\n",
              "      <td>0.441297</td>\n",
              "      <td>0.590587</td>\n",
              "      <td>-0.118730</td>\n",
              "      <td>1.010767</td>\n",
              "      <td>2.282192</td>\n",
              "      <td>-0.751310</td>\n",
              "      <td>0.141134</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.168207</td>\n",
              "      <td>0.495169</td>\n",
              "      <td>-0.066540</td>\n",
              "      <td>-0.904026</td>\n",
              "      <td>-0.149187</td>\n",
              "      <td>-0.302797</td>\n",
              "      <td>-0.188726</td>\n",
              "      <td>-0.248812</td>\n",
              "      <td>280.18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>40049</td>\n",
              "      <td>1.188332</td>\n",
              "      <td>0.360587</td>\n",
              "      <td>-0.024267</td>\n",
              "      <td>1.179898</td>\n",
              "      <td>-0.095200</td>\n",
              "      <td>-0.975171</td>\n",
              "      <td>0.403633</td>\n",
              "      <td>-0.160097</td>\n",
              "      <td>-0.460291</td>\n",
              "      <td>...</td>\n",
              "      <td>0.063470</td>\n",
              "      <td>0.115945</td>\n",
              "      <td>-0.129453</td>\n",
              "      <td>0.527456</td>\n",
              "      <td>0.748484</td>\n",
              "      <td>-0.308659</td>\n",
              "      <td>-0.022350</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>15.33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>40050</td>\n",
              "      <td>1.038810</td>\n",
              "      <td>-2.090833</td>\n",
              "      <td>0.852849</td>\n",
              "      <td>-0.847290</td>\n",
              "      <td>-2.112321</td>\n",
              "      <td>0.291188</td>\n",
              "      <td>-1.321491</td>\n",
              "      <td>0.007713</td>\n",
              "      <td>-0.771225</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059743</td>\n",
              "      <td>0.138289</td>\n",
              "      <td>-0.341212</td>\n",
              "      <td>-0.045303</td>\n",
              "      <td>0.516037</td>\n",
              "      <td>0.016258</td>\n",
              "      <td>0.051843</td>\n",
              "      <td>0.061811</td>\n",
              "      <td>236.19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>40052</td>\n",
              "      <td>1.211027</td>\n",
              "      <td>0.614544</td>\n",
              "      <td>-0.459212</td>\n",
              "      <td>0.900736</td>\n",
              "      <td>0.135725</td>\n",
              "      <td>-1.175774</td>\n",
              "      <td>0.337603</td>\n",
              "      <td>-0.198540</td>\n",
              "      <td>-0.188104</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105254</td>\n",
              "      <td>-0.214124</td>\n",
              "      <td>-0.013156</td>\n",
              "      <td>0.287419</td>\n",
              "      <td>0.453268</td>\n",
              "      <td>0.378507</td>\n",
              "      <td>-0.013994</td>\n",
              "      <td>0.042698</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39999 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e53a9e30-1c6d-42d5-8f0c-166bda049b09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e53a9e30-1c6d-42d5-8f0c-166bda049b09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e53a9e30-1c6d-42d5-8f0c-166bda049b09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "UpQW431xhV1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "missing=df.isnull().sum()\n",
        "print(missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SetA8rGJ8iLJ",
        "outputId": "124c3691-e7d0-4dca-8ff8-c3b06fc64b87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Time'], axis = 1) # drop time column\n",
        "\n",
        "# split dependent variable\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "\n",
        "# no categorical data so don't need to do any encoding"
      ],
      "metadata": {
        "id": "5I6dp-mG8uIa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4SYiLKP9cvB",
        "outputId": "58732cda-733c-4e6e-ff31-fa027a8b6931"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.35980713e+00 -7.27811733e-02  2.53634674e+00 ...  1.33558377e-01\n",
            "  -2.10530535e-02  1.49620000e+02]\n",
            " [ 1.19185711e+00  2.66150712e-01  1.66480113e-01 ... -8.98309914e-03\n",
            "   1.47241692e-02  2.69000000e+00]\n",
            " [-1.35835406e+00 -1.34016307e+00  1.77320934e+00 ... -5.53527940e-02\n",
            "  -5.97518406e-02  3.78660000e+02]\n",
            " ...\n",
            " [ 1.18833199e+00  3.60587271e-01 -2.42671732e-02 ... -2.23496673e-02\n",
            "   3.12981134e-03  1.53300000e+01]\n",
            " [ 1.03880985e+00 -2.09083275e+00  8.52849036e-01 ...  5.18432099e-02\n",
            "   6.18112614e-02  2.36190000e+02]\n",
            " [ 1.21102697e+00  6.14544124e-01 -4.59212064e-01 ... -1.39943023e-02\n",
            "   4.26975689e-02  7.60000000e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow0G0D-T9o8Z",
        "outputId": "300e6921-ac27-4632-804f-62c09bd2a68c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "3e5TsOK9-FNg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature scaling\n",
        "\n",
        "# for any neural network model we must always apply feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
        "#df = df.drop(['Time'], axis=1)\n",
        "# check that they have the same scale \n",
        "\n",
        "# imbalanced dataset try sampling with replacement\n"
      ],
      "metadata": {
        "id": "g8owdTVlhYa0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build ANN"
      ],
      "metadata": {
        "id": "JvtTXb_0_ig3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ANN\n",
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "#TODO: change number of neurons and see how it effects outcome\n",
        "\n",
        "# Adding the second hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units = 6, activation='relu'))\n",
        "\n",
        "# Adding the output layer, sigmoid allows the probab values if multi softmax\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # units is 1 because it is a binary prediction "
      ],
      "metadata": {
        "id": "6FEflZCp_19q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the ANN"
      ],
      "metadata": {
        "id": "WaC7OX34us0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the ANN\n",
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "pI_kUNP1uvCG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the ANN\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RH98DyTwemc",
        "outputId": "19d93f65-70f7-4359-d5db-74543c626245"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 5s 4ms/step - loss: 0.1005 - accuracy: 0.9794\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0062 - accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0036 - accuracy: 0.9990\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9988\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0032 - accuracy: 0.9988\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0029 - accuracy: 0.9988\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0028 - accuracy: 0.9989\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0025 - accuracy: 0.9989\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0025 - accuracy: 0.9990\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0024 - accuracy: 0.9990\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0023 - accuracy: 0.9990\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0023 - accuracy: 0.9989\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0022 - accuracy: 0.9991\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0022 - accuracy: 0.9991\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0021 - accuracy: 0.9991\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0021 - accuracy: 0.9991\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0021 - accuracy: 0.9991\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0019 - accuracy: 0.9992\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0020 - accuracy: 0.9991\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0019 - accuracy: 0.9992\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0019 - accuracy: 0.9992\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 0.9993\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0018 - accuracy: 0.9993\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0017 - accuracy: 0.9993\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0018 - accuracy: 0.9991\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0016 - accuracy: 0.9993\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0017 - accuracy: 0.9993\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0016 - accuracy: 0.9993\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9994\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0014 - accuracy: 0.9995\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0017 - accuracy: 0.9993\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0014 - accuracy: 0.9994\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0014 - accuracy: 0.9994\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0015 - accuracy: 0.9994\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0013 - accuracy: 0.9995\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0013 - accuracy: 0.9995\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0014 - accuracy: 0.9994\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0013 - accuracy: 0.9994\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0013 - accuracy: 0.9996\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0012 - accuracy: 0.9995\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0012 - accuracy: 0.9995\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0011 - accuracy: 0.9995\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.5275e-04 - accuracy: 0.9997\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.8475e-04 - accuracy: 0.9997\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0010 - accuracy: 0.9996\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.9488e-04 - accuracy: 0.9997\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.9977e-04 - accuracy: 0.9997\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.6371e-04 - accuracy: 0.9997\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 9.3518e-04 - accuracy: 0.9996\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.2740e-04 - accuracy: 0.9998\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.1736e-04 - accuracy: 0.9997\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.1214e-04 - accuracy: 0.9997\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.3905e-04 - accuracy: 0.9996\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 9.0514e-04 - accuracy: 0.9998\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.6528e-04 - accuracy: 0.9998\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.6283e-04 - accuracy: 0.9998\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.6259e-04 - accuracy: 0.9998\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.4108e-04 - accuracy: 0.9997\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.8455e-04 - accuracy: 0.9997\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8.2795e-04 - accuracy: 0.9997\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8.0583e-04 - accuracy: 0.9998\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.0236e-04 - accuracy: 0.9997\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.9330e-04 - accuracy: 0.9997\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.2710e-04 - accuracy: 0.9996\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.2810e-04 - accuracy: 0.9998\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.9693e-04 - accuracy: 0.9998\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8.3652e-04 - accuracy: 0.9997\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.4678e-04 - accuracy: 0.9997\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.0152e-04 - accuracy: 0.9997\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.5528e-04 - accuracy: 0.9997\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.7205e-04 - accuracy: 0.9997\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.2628e-04 - accuracy: 0.9998\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.0819e-04 - accuracy: 0.9998\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.2566e-04 - accuracy: 0.9997\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8.7152e-04 - accuracy: 0.9997\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.4022e-04 - accuracy: 0.9998\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.6419e-04 - accuracy: 0.9998\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.2059e-04 - accuracy: 0.9998\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.8517e-04 - accuracy: 0.9998\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.7311e-04 - accuracy: 0.9998\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 7.3319e-04 - accuracy: 0.9998\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.4414e-04 - accuracy: 0.9997\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.7998e-04 - accuracy: 0.9998\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.9847e-04 - accuracy: 0.9997\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.0607e-04 - accuracy: 0.9998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65ad873c10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ],
      "metadata": {
        "id": "tGhYplEBxmwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, the accuracy is suspiciously high. Looking at the data we can conclude that this is because there is a disporoportionate ratio of fraud observations and therfore our data is imbalanced. There are a few different solutions for this. We can change the performance metric, change the algorithm, oversample the minority class, undersample the majoirty class, or generate synthetic sample. Because of the time crunch I will try the second option and change the algorithm. Since decision trees frequently perform well on imbalanced data I will run one"
      ],
      "metadata": {
        "id": "EPfKJ41Cxrd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train,y_train)\n",
        "\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9IrzQqRm0QnG",
        "outputId": "db42ccaf-7f6e-4176-97a8-5548581d0d91"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metrics"
      ],
      "metadata": {
        "id": "0CwDWJMv3H_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej-hviTq3JSA",
        "outputId": "d6cf0748-d06e-4d21-e63b-a7a7e3bfa178"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.999375\n",
            "Precision: 0.9411764705882353\n",
            "Recall: 0.8\n",
            "F1-score: 0.8648648648648648\n",
            "AUC-ROC: 0.899937343358396\n"
          ]
        }
      ]
    }
  ]
}